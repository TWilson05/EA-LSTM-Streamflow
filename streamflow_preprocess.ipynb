{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57b8c0c5",
   "metadata": {},
   "source": [
    "# Streamflow Data Download and Preprocessing\n",
    "\n",
    "Metadata for streamflow to be downloaded from: https://wateroffice.ec.gc.ca/station_metadata/station_characteristics_e.html using the specifications `Province = Alberta`, `Parameter Type = Flows`, and `Regulation = Natural` and saved as `station_metadata.csv`.\n",
    "\n",
    "The stations listed in the metadata file subject to the date specifications are downloaded below from HYDAT and saved to `combined_streamflow.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "684cbb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data downloaded and saved to combined_streamflow.csv\n",
      "15706 days of data saved for 179 stations\n"
     ]
    }
   ],
   "source": [
    "import urllib.parse\n",
    "import pandas as pd\n",
    "\n",
    "batch_size = 50\n",
    "\n",
    "# define start and end years\n",
    "start_year = 1980\n",
    "end_year = 2022\n",
    "\n",
    "metadata = pd.read_csv(\"station_metadata.csv\")\n",
    "\n",
    "def build_wateroffice_url(stations, start_date, end_date, parameter=\"flow\"):\n",
    "    \"\"\"\n",
    "    Build a Wateroffice batch-download URL for daily data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    stations : list of str\n",
    "        List of hydrometric station numbers (e.g. [\"11AB104\", \"11AB105\"]).\n",
    "    start_date : str\n",
    "        Start date in YYYY-MM-DD.\n",
    "    end_date : str\n",
    "        End date in YYYY-MM-DD.\n",
    "    parameter : str\n",
    "        Usually \"flow\" for discharge.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        A full URL that can be used to download a combined CSV of all stations.\n",
    "    \"\"\"\n",
    "\n",
    "    base = \"https://wateroffice.ec.gc.ca/services/daily_data/csv/inline?\"\n",
    "\n",
    "    # Encode station parameters properly\n",
    "    # stations[]=11AB104&stations[]=11AB105&...\n",
    "    station_params = \"&\".join([f\"stations[]={urllib.parse.quote(s)}\" for s in stations])\n",
    "\n",
    "    # Encode parameter (e.g. flow)\n",
    "    param_part = f\"parameters[]={urllib.parse.quote(parameter)}\"\n",
    "\n",
    "    # Add date range\n",
    "    date_part = f\"start_date={start_date}&end_date={end_date}\"\n",
    "\n",
    "    url = base + station_params + \"&\" + param_part + \"&\" + date_part\n",
    "    return url\n",
    "\n",
    "def download_wateroffice_data(stations, start_date, end_date, parameter=\"flow\"):\n",
    "    url = build_wateroffice_url(stations, start_date, end_date, parameter)\n",
    "    return pd.read_csv(url)\n",
    "\n",
    "# filter the stations based on given year range\n",
    "filtered_metadata = metadata[(metadata['Year From'] <= start_year) & (metadata['Year To'] >= end_year)]\n",
    "study_stations = filtered_metadata[\"Station Number\"].tolist()\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for i in range(0, len(study_stations), batch_size):\n",
    "    batch_stations = study_stations[i:i + batch_size]\n",
    "    \n",
    "    df_batch = download_wateroffice_data(\n",
    "        batch_stations,\n",
    "        start_date=f\"{start_year}-01-01\",\n",
    "        end_date=f\"{end_year}-12-31\"\n",
    "    )\n",
    "\n",
    "    all_data.append(df_batch[[\" ID\", \"Date\", \"Value/Valeur\"]])\n",
    "    \n",
    "    # # Save each batch to a separate CSV file\n",
    "    # batch_number = i // batch_size + 1\n",
    "    # df_batch.to_csv(f\"raw_streamflow_batch_data/daily_data ({batch_number}).csv\", index=False)\n",
    "\n",
    "# Combine all files into a single long-format DataFrame\n",
    "df_long = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Convert Date to datetime to ensure proper sorting\n",
    "df_long[\"Date\"] = pd.to_datetime(df_long[\"Date\"])\n",
    "\n",
    "# Pivot into wide format: rows = dates, columns = station IDs\n",
    "df_wide = df_long.pivot(index=\"Date\", columns=\" ID\", values=\"Value/Valeur\")\n",
    "\n",
    "# Sort rows (by Date) and columns (station IDs)\n",
    "df_wide = df_wide.sort_index().sort_index(axis=1)\n",
    "\n",
    "df_wide.to_csv(\"combined_streamflow.csv\")\n",
    "\n",
    "print(\"Data downloaded and saved to combined_streamflow.csv\")\n",
    "print(f\"{df_wide.shape[0]} days of data saved for {df_wide.shape[1]-1} stations\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
